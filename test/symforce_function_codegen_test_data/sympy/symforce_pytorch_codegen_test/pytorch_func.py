# -----------------------------------------------------------------------------
# This file was autogenerated by symforce from template:
#     function/FUNCTION.py.jinja
# Do NOT modify by hand.
# -----------------------------------------------------------------------------

# pylint: disable=useless-suppression
# pylint: disable=too-many-locals
# pylint: disable=too-many-lines
# pylint: disable=too-many-statements
# pylint: disable=unused-argument

import math  # pylint: disable=unused-import
import typing as T

import torch


class TensorKwargs(T.TypedDict):
    """
    TypedDict representing args that will be passed to any torch.tensor calls
    """

    device: torch.device
    dtype: torch.dtype


def _broadcast_and_stack(tensors, dim=-1):
    # type: (T.List[torch.Tensor], int) -> torch.Tensor
    """
    broadcast tensors to common shape then stack along new dimension
    """

    broadcast_shape = torch.broadcast_shapes(*(x.size() for x in tensors))
    broadcast_tensors = [x.broadcast_to(broadcast_shape) for x in tensors]

    return torch.stack(broadcast_tensors, dim=dim)


def pytorch_func(a, b, c, d, e, f, tensor_kwargs=None):
    # type: (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, T.Optional[TensorKwargs]) -> T.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
    """
    This function was autogenerated from a symbolic function. Do not modify by hand.

    Symbolic function: pytorch_func

    Args:
        a: Scalar
        b: Matrix11
        c: Matrix31
        d: Matrix22
        e: Matrix51
        f: Matrix66

    Outputs:
        a_out: Scalar
        b_out: Matrix11
        c_out: Matrix31
        d_out: Matrix22
        e_out: Matrix51
        f_out: Matrix66

    The types for inputs and outputs above are the shapes of the symbolic matrices this function was
    generated from.  Tensors for both inputs and outputs are expected to have dimensions as follows:

    - (..., N, M) for sf.Matrix types of shape (N, M) where N != 1 and M != 1
    - (..., N) for sf.Matrix types of shape (N, M) where N != 1 and M == 1 (i.e. column vectors)
    - (..., M) for sf.Matrix types of shape (N, M) where N == 1 and M != 1 (i.e. row vectors)
    - (...) for sf.Matrix types of shape (1, 1) and sf.Scalar types

    Where `...` is an arbitrary number of batch dimensions that can be present on the front of input
    tensors.  The outputs will have the same batch dimensions as the inputs.

    The tensor_kwargs argument can be used to set the device and dtype to use.  If not provided, it will
    default to the device and dtype of the first input tensor, or the empty dict if there are no inputs.
    """

    # Total ops: 0

    # Deduce expected tensor device and dtype if not provided
    if tensor_kwargs is None:
        tensor_kwargs = {"device": a.device, "dtype": a.dtype}

    # Input arrays

    # Intermediate terms (0)

    # Output terms
    _a_out = a
    _b_out = b
    _c_out = _broadcast_and_stack([c[..., 0], c[..., 1], c[..., 2]], dim=-1)
    _d_out = _broadcast_and_stack(
        [
            _broadcast_and_stack([d[..., 0, 0], d[..., 1, 0]], dim=-1),
            _broadcast_and_stack([d[..., 0, 1], d[..., 1, 1]], dim=-1),
        ],
        dim=-1,
    )
    _e_out = _broadcast_and_stack([e[..., 0], e[..., 1], e[..., 2], e[..., 3], e[..., 4]], dim=-1)
    _f_out = _broadcast_and_stack(
        [
            _broadcast_and_stack(
                [
                    f[..., 0, 0],
                    f[..., 1, 0],
                    f[..., 2, 0],
                    f[..., 3, 0],
                    f[..., 4, 0],
                    f[..., 5, 0],
                ],
                dim=-1,
            ),
            _broadcast_and_stack(
                [
                    f[..., 0, 1],
                    f[..., 1, 1],
                    f[..., 2, 1],
                    f[..., 3, 1],
                    f[..., 4, 1],
                    f[..., 5, 1],
                ],
                dim=-1,
            ),
            _broadcast_and_stack(
                [
                    f[..., 0, 2],
                    f[..., 1, 2],
                    f[..., 2, 2],
                    f[..., 3, 2],
                    f[..., 4, 2],
                    f[..., 5, 2],
                ],
                dim=-1,
            ),
            _broadcast_and_stack(
                [
                    f[..., 0, 3],
                    f[..., 1, 3],
                    f[..., 2, 3],
                    f[..., 3, 3],
                    f[..., 4, 3],
                    f[..., 5, 3],
                ],
                dim=-1,
            ),
            _broadcast_and_stack(
                [
                    f[..., 0, 4],
                    f[..., 1, 4],
                    f[..., 2, 4],
                    f[..., 3, 4],
                    f[..., 4, 4],
                    f[..., 5, 4],
                ],
                dim=-1,
            ),
            _broadcast_and_stack(
                [
                    f[..., 0, 5],
                    f[..., 1, 5],
                    f[..., 2, 5],
                    f[..., 3, 5],
                    f[..., 4, 5],
                    f[..., 5, 5],
                ],
                dim=-1,
            ),
        ],
        dim=-1,
    )

    return _a_out, _b_out, _c_out, _d_out, _e_out, _f_out
